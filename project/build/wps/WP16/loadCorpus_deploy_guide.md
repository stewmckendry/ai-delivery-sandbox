# Deploy Guide: `loadCorpus` and Vector Store Setup

## 1. ğŸ§  Vector Store Engine
- **Default (Dev)**: FAISS (local, fast, open-source)
- **Cloud Option**: Chroma + Docker + Volume Mount or Postgres

## 2. ğŸ“¦ Setup Instructions (FAISS, Dev Mode)
```bash
pip install faiss-cpu numpy openai
```

## 3. ğŸŒ Setup Instructions (Chroma, Cloud Mode)
```bash
pip install chromadb
```

### Option A â€“ Local Docker (for Railway or Azure container app)
- Use a `docker-compose.yaml` to mount persistent volume
- Example:
```yaml
services:
  chroma:
    image: chromadb/chroma
    ports:
      - "8000:8000"
    volumes:
      - ./data/chroma:/chroma/chroma
```

### Option B â€“ Remote DB (Chroma + Postgres)
- Set `.env`:
```env
CHROMA_SERVER_HOST=https://your-deployed-url
CHROMA_SERVER_HTTP_PORT=8000
```
- Use `Settings` in `loadCorpus` to connect with API client

## 4. ğŸ” Authorization (Embedding)
```env
OPENAI_API_KEY=sk-...
```

## 5. ğŸ“ Directory Layout (Dev Mode)
- Vector index files: `data/vector_store/index.faiss`
- Metadata: `data/vector_store/index.json`

## 6. ğŸ”„ Refresh Strategy
- Index updated on each `loadCorpus` call
- Remote stores push on add/update

## 7. ğŸ” Retrieval Integration
- Planner tools will query based on metadata tags
- Match section, intent, gate, etc.

## 8. ğŸ§ª Verification
```bash
python app/tools/tool_wrappers/loadCorpus.py --test
```
Expected:
- FAISS or Chroma index update
- Log in PromptLog
- Embedding count returned

---
âœ… Guide supports dev and cloud. Use .env to switch configs.