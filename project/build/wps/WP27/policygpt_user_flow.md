## PolicyGPT End-to-End User Journey

This guide describes how users interact with the PolicyGPT assistant to go from a blank slate to a fully drafted and refined artifact. It outlines each step of the journey, the conversations the user might have with the GPT assistant, the tools/chains being invoked, and whatâ€™s happening in the background.

---

### ğŸ›« 1. Chat Begins: Context and Gate Setup
**User says:** â€œI need help drafting materials for a Cabinet submission.â€

**GPT replies:** â€œWhich policy gate are you preparing for? For example: Gate 1, 2, or 3?â€

**Tool called:** `inputPromptGenerator`
- **Purpose:** Fetches the list of artifacts, sections, and metadata for the selected gate from `gate_reference_v2.yaml`.
- **Inputs:** `{ gate_id }`
- **Background:** GPT uses this map to serve as a navigator for the artifact generation and review.

---

### ğŸ—‚ 2. Upload Project-Specific Inputs
**User says:** â€œHereâ€™s our program backgrounder and stakeholder notes.â€

**GPT replies:** â€œUploading and indexing these as references.â€

**Tool(s) called:**
- `ingestInput` (for structured fields)
- `uploadInputPDF`, `uploadInputDocx`, `uploadInputText`

**Background:**
- Content is parsed, chunked, and saved to Redis or vector DB.
- Metadata is stored for later recall.

---

### ğŸ“š 3. Load Corpus (Landmark Documents)
**User says:** â€œHereâ€™s the 2025 mandate letter and strategy doc.â€

**GPT calls:** `loadCorpus`
- **Inputs:** Can accept full text or URLs (TBD extension)
- **Background:**
  - Texts are chunked and embedded.
  - Stored in a vector DB with tags for later querying.

---

### ğŸŒ 4. Build Global Context (Optional Research)
**User says:** â€œWhatâ€™s already been done on this issue?â€

**GPT calls:** `global_context_chain` â†’ runs:
- `web_search`
- `goc_alignment_search`

**Background:**
- Controlled prompt templates used.
- Results saved and linked to inputs.
- Indexed for reuse.

---

### âœï¸ 5. Draft Each Section
**User says:** â€œLetâ€™s start drafting the Problem Statement.â€

**GPT calls:** `generate_section_chain`
- **Steps:** Retrieves memory, inputs, corpus matches, and prompts the LLM.
- **Saves to:** `ArtifactSection` (DB) and `Redis` (live draft)

---

### ğŸ§  6. Review and Revise Each Section
**User says:** â€œThat could be clearer. Add stakeholder evidence.â€

**GPT calls:** `revise_section_chain`
- **Tools used:**
  - `feedback_structurer` â€“ breaks down feedback and assigns sections.
  - `section_rewriter` â€“ rewrites based on revision type.
  - `diff_summarizer` â€“ stores summary in Redis.
  - `save_artifact_and_trace`

**Stored in:**
- `ArtifactSection` (DB)
- Redis (as in-memory â€œreviewâ€ version)

**To retrieve:** `fetch_review_section`, `list_review_sections`

---

### ğŸ“ƒ 7. Finalize the Document
**User says:** â€œLooks good. Letâ€™s finalize.â€

**GPT calls:** `assemble_artifact_chain`
- Loads section metadata from DB + Redis
- Calls `formatSection`, `mergeSections`, `finalizeDocument`
- Saves to Google Drive via `storeToDrive`

---

### ğŸ” 8. Return With Feedback
**User says:** â€œHereâ€™s reviewer feedback from our director.â€

**GPT replies:** â€œParsing and applying feedback.â€

**Tool:** `revise_section_chain` again
- Feedback is restructured, mapped, rewritten, and diffed
- Trace is logged

---

### ğŸ§­ Alternative Paths
- Skip research phase
- Use only uploaded inputs
- Manual edits via `manualEditSync`

---

This design supports async work, stakeholder feedback, traceable changes, and alignment to reference material.