# ğŸ§  Task 324: Improve Vector Prompt Quality for Small Record Sets

## ğŸ§  Context
The AI Health Records Assistant uses Chroma for semantic retrieval in `/ask_vector`. In cases where only 1â€“3 records are returned (such as in demo mode), GPT often fails to extract useful meaning.

The repo is `ai-delivery-sandbox`, branch `sandbox-curious-fox`.

## ğŸ“ Issues Observed
- Chunks are often short (1â€“2 lines)
- Metadata like "Procedure" or "ER note" is not surfaced in GPT context
- Semantic distance between query and record (e.g., â€œankle injuryâ€ vs â€œsprained ankleâ€) is not bridged by GPT

## âœ… Goal
Improve prompt quality in `/ask_vector` so that even small, sparse records still return meaningful GPT answers.

---

## ğŸ“¦ What to Do

### 1. Improve Prompt Assembly in `rag.py`
Update the GPT prompt passed to include structured context per record:
```txt
Record 1:
Type: Procedure
Code: 6142004
Text: Patient treated for sprained ankle. Discharged with crutches.
```
Do this for every chunk returned by Chroma before inserting into the final GPT call.

### 2. Expand Metadata in Indexer
Update `index_structured_records` in `rag/indexer.py` to include additional fields:
- `display`
- `source_url`
- (Optional) source portal type: "ER", "lab", etc.

This will allow richer prompt framing and match whatâ€™s useful to GPT.

### 3. Add Richer Demo Content
As a fallback for minimal test data:
- Add 2â€“3 demo records per test PDF
- Use variant phrasing (e.g., â€œsprained ankleâ€ vs â€œankle injuryâ€)
- Optionally add more descriptive sentences (e.g., â€œSeen at ER on March 10, discharged with crutches.â€)

---

## ğŸ§ª Done When
- GPT answers can accurately respond to demo questions like:
  - â€œDid I visit the ER?â€
  - â€œWhat happened during my hospital visit?â€
- Prompt fed to GPT includes both metadata and record text
- Small sessions return meaningful answers via `/ask_vector`

Let Stewart know when this is deployed so we can revalidate prompt outcomes with minimal records.